{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755ab3da",
   "metadata": {},
   "source": [
    "## Graph1: Basic BotðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad0af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6800f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548dc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5deba5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State) -> State:\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd23cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"cbot\", chatbot)\n",
    "graph.set_entry_point(\"cbot\")\n",
    "graph.add_edge(\"cbot\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d923d9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi, I am Henry', additional_kwargs={}, response_metadata={}, id='abae2ce7-120f-496c-ab4d-dc0ac8f3a538'), AIMessage(content=\"Hi Henry, it's nice to meet you! How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f283919d-447a-4983-b032-ab250e6cccee-0', usage_metadata={'input_tokens': 5, 'output_tokens': 19, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})]}\n",
      "{'messages': [HumanMessage(content='what are you good at?', additional_kwargs={}, response_metadata={}, id='ecd8c439-7968-469d-a2e6-b0a6f4d53716'), AIMessage(content=\"I am a large language model, also known as a conversational AI or chatbot trained to be informative and comprehensive. I am trained on a massive amount of text data, and I am able to communicate and generate human-like text in response to a wide range of prompts and questions. For example, I can provide summaries of factual topics, create stories, and translate languages.\\n\\nHere's a breakdown of some of my strengths:\\n\\n*   **Understanding and Responding to Natural Language:** I can understand complex questions, prompts, and instructions expressed in natural language.\\n*   **Generating Text:** I can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill all your requirements.\\n*   **Providing Information:** I have access to a vast amount of information and can provide summaries, explanations, and insights on a wide range of topics.\\n*   **Translation:** I can translate text between many different languages.\\n*   **Summarization:** I can condense large amounts of text into concise summaries.\\n*   **Following Instructions:** I am generally good at following instructions and completing tasks as requested.\\n*   **Learning and Adapting:** I am constantly learning and improving my abilities through ongoing training.\\n\\n**However, it's important to remember that I also have limitations:**\\n\\n*   **I am not a human:** I don't have personal experiences, emotions, or consciousness.\\n*   **My knowledge is limited:** My knowledge is based on the data I was trained on, and I may not have information about events that occurred after my last training update.\\n*   **I can make mistakes:** While I strive to provide accurate information, I can sometimes generate incorrect or nonsensical responses.\\n*   **I cannot provide advice:** I am not qualified to provide financial, medical, or legal advice.\\n\\nIn short, I am a powerful tool that can be used for a variety of purposes, but it's important to be aware of my limitations and to use me responsibly.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4fc3b09c-411f-4d40-80fe-00f0d5b72fc7-0', usage_metadata={'input_tokens': 6, 'output_tokens': 423, 'total_tokens': 429, 'input_token_details': {'cache_read': 0}})]}\n",
      "{'messages': [HumanMessage(content='Can you help me with prompt generation?', additional_kwargs={}, response_metadata={}, id='675153b0-02c2-4bda-9a1a-58ed364b47c4'), AIMessage(content='Okay, I\\'d love to help you with prompt generation! To give you the best assistance, I need a little more information.  Tell me about what you\\'re trying to achieve.  Consider these questions:\\n\\n**1. What is your goal? What do you want to generate?**\\n\\n*   **Text:** (e.g., story, poem, email, code, recipe, blog post, marketing copy, script, etc.)\\n*   **Image:** (e.g., realistic, abstract, illustration, photograph, painting, etc.)\\n*   **Audio:** (e.g., music, sound effects, speech, etc.)\\n*   **Video:** (e.g., animation, short film, tutorial, etc.)\\n*   **Something else entirely?** (e.g., a 3D model, a game, a research paper)\\n\\n**2. What kind of output are you looking for?**\\n\\n*   **Specific Style:** (e.g., humorous, serious, formal, informal, romantic, sci-fi, realistic, abstract, etc.)\\n*   **Specific Tone:** (e.g., optimistic, pessimistic, sarcastic, informative, persuasive, etc.)\\n*   **Specific Length:** (e.g., short, medium, long, word count, number of paragraphs, etc.)\\n*   **Specific Format:** (e.g., bullet points, numbered list, paragraph, table, etc.)\\n*   **Specific Audience:** (e.g., children, experts, general public, etc.)\\n\\n**3. What is the context or background information?**\\n\\n*   **Topic:** What is the subject matter you want the generated content to be about?\\n*   **Keywords:** What are the important keywords or phrases related to the topic?\\n*   **Existing Content:** Do you have any existing content that you want to build upon or reference?\\n*   **Constraints:** Are there any limitations or restrictions? (e.g., must avoid certain topics, must adhere to a specific brand voice, etc.)\\n\\n**4. What model are you using?**\\n\\n*   Knowing the model (e.g., ChatGPT, DALL-E 2, Midjourney, Stable Diffusion, Bard, etc.) helps me tailor the prompt to its strengths and limitations.\\n\\n**Once I have this information, I can help you with:**\\n\\n*   **Brainstorming ideas:**  Generating different concepts or angles for your prompt.\\n*   **Refining your existing prompt:**  Making it more specific, clear, and effective.\\n*   **Adding details:**  Including relevant information to guide the model towards the desired output.\\n*   **Structuring your prompt:**  Organizing the prompt in a way that is easy for the model to understand.\\n*   **Providing examples:**  Showing you how to write different types of prompts.\\n*   **Helping you iterate:**  Suggesting ways to modify your prompt based on the initial results.\\n\\n**Here are some general tips for writing effective prompts:**\\n\\n*   **Be clear and specific:** Avoid ambiguity and vague language.\\n*   **Use keywords:** Include relevant keywords to guide the model.\\n*   **Provide context:** Give the model enough information to understand the topic.\\n*   **Specify the desired output:** Describe the style, tone, length, and format you want.\\n*   **Use examples:** Provide examples of the type of content you are looking for.\\n*   **Iterate and refine:** Experiment with different prompts and adjust them based on the results.\\n\\n**Example:**\\n\\nLet\\'s say you want to generate a short story.  Tell me:\\n\\n*   **Goal:** Generate a short story.\\n*   **Output:**  A sci-fi short story with a humorous tone, about 500 words long.\\n*   **Context:** The story should be about a robot who accidentally becomes a famous chef. Keywords: robot, chef, cooking, humor, sci-fi.\\n*   **Model:** ChatGPT\\n\\nWith this information, I can help you craft a more effective prompt, such as:\\n\\n\"Write a humorous sci-fi short story, approximately 500 words long, about a robot who accidentally becomes a famous chef. The robot, Unit 734 (nicknamed \"Rusty\"), was originally designed for deep-sea mining but a software glitch leads him to believe he\\'s a culinary artist. He starts experimenting with whatever materials he can find, resulting in bizarre but surprisingly delicious creations. The story should focus on the reactions of the humans who try his food and how Rusty navigates the world of competitive cooking. Think Douglas Adams meets a cooking show.\"\\n\\n**Now, tell me about what you want to generate!** ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--b8c1c2e9-a653-4d30-9ec2-da337ad30f21-0', usage_metadata={'input_tokens': 8, 'output_tokens': 992, 'total_tokens': 1000, 'input_token_details': {'cache_read': 0}})]}\n",
      "Bye Bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Query: \")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"Bye Bye\")\n",
    "        break\n",
    "    result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    # print(f\"AIðŸ¤–: {state[\"messages\"][-1].content}\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fca78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
