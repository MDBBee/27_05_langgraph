{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59146d1c",
   "metadata": {},
   "source": [
    "# Supervisor Multiagent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830f08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, List, Literal \n",
    "from pydantic import BaseModel, Field \n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults \n",
    "from langgraph.types import Command \n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from IPython.display import Image, display \n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bdd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(BaseModel):\n",
    "    next: Literal[\"enhancer\", \"researcher\", \"coder\"] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence: \"\n",
    "                    \"'enhancer' when user input requires clarification, expansion, or refinement, \"\n",
    "                    \"'researcher' when additional facts, context, or data collection is necessary, \"\n",
    "                    \"'coder' when implementation, computation, or technical problem-solving is required.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state: MessagesState) -> Command[Literal[\"enhancer\", \"researcher\", \"coder\"]]:\n",
    "\n",
    "    system_prompt = ('''\n",
    "                 \n",
    "        You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\n",
    "\n",
    "        **Team Members**:\n",
    "        1. **Prompt Enhancer**: Always consider this agent first. They clarify ambiguous requests, improve poorly defined queries, and ensure the task is well-structured before deeper processing begins.\n",
    "        2. **Researcher**: Specializes in information gathering, fact-finding, and collecting relevant data needed to address the user's request.\n",
    "        3. **Coder**: Focuses on technical implementation, calculations, data analysis, algorithm development, and coding solutions.\n",
    "\n",
    "        **Your Responsibilities**:\n",
    "        1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "        2. Route the task to the most appropriate agent at each decision point.\n",
    "        3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "        4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "        Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing unnecessary steps, ultimately delivering complete and accurate solutions to user requests.\n",
    "                 \n",
    "    ''')\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"] \n",
    "\n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    print(f\"--- Workflow Transition: Supervisor → {goto.upper()} ---\")\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,  \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancer_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Enhancer agent node that improves and clarifies user queries.\n",
    "        Takes the original user input and transforms it into a more precise,\n",
    "        actionable request before passing it to the supervisor.\n",
    "    \"\"\"\n",
    "   \n",
    "    system_prompt = (\n",
    "        \"You are a Query Refinement Specialist with expertise in transforming vague requests into precise instructions. Your responsibilities include:\\n\\n\"\n",
    "        \"1. Analyzing the original query to identify key intent and requirements\\n\"\n",
    "        \"2. Resolving any ambiguities without requesting additional user input\\n\"\n",
    "        \"3. Expanding underdeveloped aspects of the query with reasonable assumptions\\n\"\n",
    "        \"4. Restructuring the query for clarity and actionability\\n\"\n",
    "        \"5. Ensuring all technical terminology is properly defined in context\\n\\n\"\n",
    "        \"Important: Never ask questions back to the user. Instead, make informed assumptions and create the most comprehensive version of their request possible.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"]  \n",
    "\n",
    "    enhanced_query = llm.invoke(messages)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Prompt Enhancer → Supervisor ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [  \n",
    "                HumanMessage(\n",
    "                    content=enhanced_query.content, \n",
    "                    name=\"enhancer\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\", \n",
    "    )\n",
    "\n",
    "# 2) RESEARCHER\n",
    "def research_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Research agent node that gathers information using Tavily search.\n",
    "        Takes the current task state, performs relevant research,\n",
    "        and returns findings for validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    research_agent = create_react_agent(\n",
    "        llm,  \n",
    "        tools=[tavily_search],  \n",
    "        state_modifier= \"You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n\"\n",
    "            \"1. Identifying key information needs based on the query context\\n\"\n",
    "            \"2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n\"\n",
    "            \"3. Organizing findings in a structured, easily digestible format\\n\"\n",
    "            \"4. Citing sources when possible to establish credibility\\n\"\n",
    "            \"5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\n\"\n",
    "            \"Provide thorough, factual responses without speculation where information is unavailable.\"\n",
    "    )\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Researcher → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [ \n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content,  \n",
    "                    name=\"researcher\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\", \n",
    "    )\n",
    "\n",
    "\n",
    "# 3)CODER\n",
    "def code_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    code_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        state_modifier=(\n",
    "            \"You are a coder and analyst. Focus on mathematical calculations, analyzing, solving math questions, \"\n",
    "            \"and executing code. Handle technical problem-solving and data tasks.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Coder → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATOR\n",
    "system_prompt = '''\n",
    "    Your task is to ensure reasonable quality. \n",
    "    Specifically, you must:\n",
    "    - Review the user's question (the first message in the workflow).\n",
    "    - Review the answer (the last message in the workflow).\n",
    "    - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "    - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "    \n",
    "    - Accept answers that are \"good enough\" rather than perfect\n",
    "    - Prioritize workflow completion over perfect responses\n",
    "    - Give benefit of doubt to borderline answers\n",
    "    \n",
    "    Routing Guidelines:\n",
    "    1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "    2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "'''\n",
    "\n",
    "class Validator(BaseModel):\n",
    "    next: Literal[\"supervisor\", \"FINISH\"] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"The reason for the decision.\"\n",
    "    )\n",
    "\n",
    "def validator_node(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "\n",
    "    user_question = state[\"messages\"][0].content\n",
    "    agent_answer = state[\"messages\"][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "        {\"role\": \"assistant\", \"content\": agent_answer},\n",
    "    ]\n",
    "\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == \"FINISH\" or goto == END:\n",
    "        goto = END  \n",
    "        print(\" --- Transitioning to END ---\")  \n",
    "    else:\n",
    "        print(f\"--- Workflow Transition: Validator → Supervisor ---\")\n",
    " \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"validator\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ec449",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node) \n",
    "graph.add_node(\"enhancer\", enhancer_node)  \n",
    "graph.add_node(\"researcher\", research_node) \n",
    "graph.add_node(\"coder\", code_node) \n",
    "graph.add_node(\"validator\", validator_node)  \n",
    "\n",
    "graph.add_edge(START, \"supervisor\")  \n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Weather in Chennai\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        last_message = value.get(\"messages\", [])[-1] if \"messages\" in value else None\n",
    "        if last_message:\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(last_message, indent=2, width=80, depth=None)\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
